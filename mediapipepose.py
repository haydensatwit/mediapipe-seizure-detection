# -*- coding: utf-8 -*-
"""MediapipePose.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YkbkpggwmqayLeFNHPopkB1E1E6hQFOm

Code for running locally
"""
import cv2
import time
import sys
import mediapipe as mp
import numpy as np

from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2

def draw_landmarks_on_image(rgb_image, detection_result):
    pose_landmarks_list = detection_result.pose_landmarks
    annotated_image = np.copy(rgb_image)
    ret = ''

    # Loop through the detected poses to visualize.
    for idx in range(len(pose_landmarks_list)):
        pose_landmarks = pose_landmarks_list[idx]

        # Draw the pose landmarks.
        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
        pose_landmarks_proto.landmark.extend([
            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks
        ])
        ret += str(pose_landmarks_proto)
        solutions.drawing_utils.draw_landmarks(
        annotated_image,
        pose_landmarks_proto,
        solutions.pose.POSE_CONNECTIONS,
        solutions.drawing_styles.get_default_pose_landmarks_style())
    return (annotated_image, ret)

model_path = './pose_landmarker.task'

def main():
    detection_result_list = []
    frame_list = []

    counter, fps = 0, 0

    start_time = time.time()
    offset_delay = 1000
    cap = cv2.VideoCapture(0)

    # Visualization parameters
    row_size = 20  # pixels
    left_margin = 24  # pixels
    right_margin = 408 # pixels
    text_color = (0, 0, 255)  # red
    font_size = 1
    font_thickness = 1
    fps_avg_frame_count = 10

    BaseOptions = mp.tasks.BaseOptions
    PoseLandmarker = mp.tasks.vision.PoseLandmarker
    PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions
    PoseLandmarkerResult = mp.tasks.vision.PoseLandmarkerResult
    VisionRunningMode = mp.tasks.vision.RunningMode

    def result_callback(result: PoseLandmarkerResult, output_image: mp.Image, timestamp_ms: int):
        result.timestamp_ms = timestamp_ms
        detection_result_list.clear()
        detection_result_list.append(result)

    options = PoseLandmarkerOptions(
        base_options=BaseOptions(model_asset_path=model_path),
        running_mode=VisionRunningMode.LIVE_STREAM,
        result_callback=result_callback)
    
    landmarker = vision.PoseLandmarker.create_from_options(options)

    # Point Lists
    left_y_list = []
    right_y_list = []
    nose_x_list = []
    left_eye_x_list = []
    right_eye_x_list = []
    left_mouth_x_list = []
    right_mouth_x_list = []
    # Thresholds
    sample_size = 10
    disp_threshold = .03
    speed_threshold = .5
    # Warning Values
    warn_val = 0
    head_warn_val = 0
    warn_threshold = 80
    warn_cap = 20
    # Seizure detection
    seize_start = -1.0
    seize_end = -1.0
    seize_dur = -1.0
    seize_thresh = 0.0

    while cap.isOpened():
        ret, img = cap.read()

        if not ret:
           sys.exit('ERROR: Unable to read from webcam. Please verify your webcam settings.')

        counter += 1

        img = cv2.flip(img, 1)

        # convert default bgr image capture to rgb
        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_img)

        #output_value = coordinate_landmarker.detect(mp_img)
        landmarker.detect_async(mp_img, counter)

        current_frame = mp_img.numpy_view()
        current_frame = cv2.cvtColor(current_frame, cv2.COLOR_RGB2BGR)
        frame_list.append(current_frame)

        # Calculate the FPS
        if counter % fps_avg_frame_count == 0:
            end_time = time.time()
            fps = fps_avg_frame_count / (end_time - start_time)
            start_time = time.time()

        # Show the FPS
        fps_text = 'FPS = {:.1f}'.format(fps)
        text_location = (left_margin, row_size)
        cv2.putText(frame_list[0], fps_text, text_location, cv2.FONT_HERSHEY_PLAIN,
                    font_size, text_color, font_thickness)
        right_output_location = (left_margin, row_size * 2)
        left_output_location = (left_margin, row_size * 3)

        if detection_result_list:
            # Draws pose on image, gets landmark data
            temp = draw_landmarks_on_image(frame_list.pop(0), detection_result_list[0])
            vis_img = temp[0]
            output_data = temp[1].split('landmark')
            output_data.pop(0)
            # Checks if landmark data is valid
            if len(output_data) > 12:
                # Gets x values for head, y values for shoulders
                parse = output_data[0].split('x: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                nose_x_list.append(coordinate)

                parse = output_data[2].split('x: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                left_eye_x_list.append(coordinate)
                
                parse = output_data[5].split('x: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                right_eye_x_list.append(coordinate)
                
                parse = output_data[9].split('x: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                left_mouth_x_list.append(coordinate)
                
                parse = output_data[10].split('x: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                right_mouth_x_list.append(coordinate)

                parse = output_data[11].split('y: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                left_y_list.append(coordinate)

                parse = output_data[12].split('y: ')
                parse = parse[1].split(' ')
                coordinate = float(parse[0])
                right_y_list.append(coordinate)
                
                # Checks if the sample size req is met
                if len(right_y_list) >= sample_size + 1:
                    right_speed = 0
                    left_speed = 0
                    nose_speed = 0
                    left_eye_speed = 0
                    right_eye_speed = 0
                    left_mouth_speed = 0
                    right_mouth_speed = 0
                    i = 0

                    # Gets max displacement across sample size
                    right_disp = max(right_y_list) - min(right_y_list)
                    left_disp = max(left_y_list) - min(left_y_list)
                    nose_disp = max(nose_x_list) - min(nose_x_list)
                    left_eye_disp = max(left_eye_x_list) - min(left_eye_x_list)
                    right_eye_disp = max(right_eye_x_list) - min(right_eye_x_list)
                    left_mouth_disp = max(left_mouth_x_list) - min(left_mouth_x_list)
                    right_mouth_disp = max(right_mouth_x_list) - min(right_mouth_x_list)

                    # Gets total distance traveled by each point
                    while i < sample_size:
                        right_speed += abs(right_y_list[i+1] - right_y_list[i])
                        left_speed += abs(left_y_list[i+1] - left_y_list[i])
                        nose_speed += abs(nose_x_list[i+1] - nose_x_list[i])
                        right_eye_speed += abs(right_eye_x_list[i+1] - right_eye_x_list[i])
                        left_eye_speed += abs(left_eye_x_list[i+1] - left_eye_x_list[i])
                        right_mouth_speed += abs(right_mouth_x_list[i+1] - right_mouth_x_list[i])
                        left_mouth_speed += abs(left_mouth_x_list[i+1] - left_mouth_x_list[i])
                        i += 1
                    
                    # Converts distance to an average speed
                    right_speed /= sample_size * (1 / fps)
                    left_speed /= sample_size * (1 / fps)
                    nose_speed /= sample_size * (1 / fps)
                    right_eye_speed /= sample_size * (1 / fps)
                    left_eye_speed /= sample_size * (1 / fps)
                    right_mouth_speed /= sample_size * (1 / fps)
                    left_mouth_speed /= sample_size * (1 / fps)

                    # Discards oldest frame
                    right_y_list.pop(0)
                    left_y_list.pop(0)
                    nose_x_list.pop(0)
                    right_eye_x_list.pop(0)
                    left_eye_x_list.pop(0)
                    right_mouth_x_list.pop(0)
                    left_mouth_x_list.pop(0)

                    # Checks if speed and displacement are above a threshold, adjust warning value
                    if right_speed >= speed_threshold and right_disp >= disp_threshold:
                        warn_val += 2
                    elif left_speed >= speed_threshold and left_disp >= disp_threshold:
                        warn_val += 2
                    else:
                        warn_val -= 2
                    if warn_val > warn_threshold + warn_cap:
                        warn_val = warn_threshold + warn_cap
                    elif warn_val < 0:
                        warn_val = 0
                    
                    # Takes average and displacement of head, adjusts warning value
                    avg_head_speed = (nose_speed + right_eye_speed + left_eye_speed + right_mouth_speed + left_mouth_speed)/5
                    avg_head_disp = (nose_disp + right_eye_disp + left_eye_disp + right_mouth_disp + left_mouth_disp)/5
                    if avg_head_speed >= speed_threshold and avg_head_disp > disp_threshold:
                        head_warn_val += 2
                    else:
                        head_warn_val -= 2
                    if head_warn_val > warn_threshold + warn_cap:
                        head_warn_val = warn_threshold + warn_cap
                    elif head_warn_val < 0:
                        head_warn_val = 0
                        
                    right_speed_text = 'R-S Speed = : {:.3f}'.format(right_speed)
                    left_speed_text = 'L-S Speed = : {:.3f}'.format(left_speed)
                    if right_speed >= speed_threshold:
                        right_color = text_color
                    else:
                        percentage = (speed_threshold - right_speed) / speed_threshold
                        right_color = (0, 255 * percentage, 255 * (1 - percentage))
                    if left_speed >= speed_threshold:
                        left_color = text_color
                    else:
                        percentage = (speed_threshold - left_speed) / speed_threshold
                        left_color = (0, 255 * percentage, 255 * (1 - percentage))
                    #cv2.putText(frame_list[0], right_speed_text, right_output_location, cv2.FONT_HERSHEY_PLAIN,
                    #    font_size, right_color, font_thickness)
                    #cv2.putText(frame_list[0], left_speed_text, left_output_location, cv2.FONT_HERSHEY_PLAIN,
                    #    font_size, left_color, font_thickness)
                    
                    # Displays warning value
                    warn_text_color = (0, 255, 0)
                    head_warn_text_color = (0, 255, 0)
                    warn_text = 'S Warning Value: {:d}'.format(warn_val)
                    head_warn_text = 'H Warning Value: {:d}'.format(head_warn_val)
                    if warn_val >= warn_threshold:
                        warn_text += '!!!'
                        warn_text_color = (0, 0, 255)
                    if head_warn_val >= warn_threshold:
                        head_warn_text += '!!!'
                        head_warn_text_color = (0, 0, 255)
                    cv2.putText(frame_list[0], warn_text, (right_margin, row_size), cv2.FONT_HERSHEY_PLAIN,
                        font_size, warn_text_color, font_thickness)
                    cv2.putText(frame_list[0], head_warn_text, (right_margin, row_size * 2), cv2.FONT_HERSHEY_PLAIN,
                        font_size, head_warn_text_color, font_thickness)
                    
                    # Checks if both warning values surpass threshold
                    seize_text_color = (0, 255, 0)
                    if warn_val >= warn_threshold and head_warn_val >= warn_threshold:
                        # Marks start of seizure
                        if seize_start <= seize_end:
                            seize_start = time.time()
                        # Checks if duration surpasses threshold
                        if time.time() > seize_start + seize_thresh:
                            seize_dur = time.time() - (seize_start + seize_thresh)
                            # Text color is different for active seizure
                            seize_text_color = (0, 0, 255)
                    # Checks if seizure has ended
                    elif seize_end < seize_start:
                        # Sets end time and duration
                        seize_end = time.time()
                        if (seize_end - seize_start > seize_thresh):
                            seize_dur = seize_end - (seize_start + seize_thresh)
                    # Prints seizure duration
                    seize_text = 'Seizure Duration: {:.2f}'.format(seize_dur)
                    if seize_dur > 0:
                        cv2.putText(frame_list[0], seize_text, (right_margin // 2, row_size * 20), cv2.FONT_HERSHEY_PLAIN,
                        font_size, seize_text_color, font_thickness)
            cv2.imshow('pose detection', vis_img)
        elif time.time() > start_time + offset_delay:
            cv2.imshow('pose detection', frame_list.pop(0))

        if cv2.waitKey(1) == 27:
            break

    landmarker.close()
    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
